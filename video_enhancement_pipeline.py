#!/usr/bin/env python3
"""
–ì–æ—Ç–æ–≤—ã–π CLI pipeline –¥–ª—è FastDVDnet + RealBasicVSR x2
–¢–æ—á–Ω–æ –ø–æ –ø–ª–∞–Ω—É: –¥–µ–Ω–æ–π–∑–∏–Ω–≥ -> –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥ x2 -> –∏—Ç–æ–≥–æ–≤–æ–µ –≤–∏–¥–µ–æ
"""
import os
import sys
import argparse
import torch
import cv2
import numpy as np
from pathlib import Path
import subprocess
import tempfile

def setup_models():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ FastDVDnet –∏ RealBasicVSR"""
    print("üîß –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    
    models = {}
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º FastDVDnet (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
    try:
        if os.path.exists('fastdvdnet_traced.pt'):
            models['fastdvdnet'] = torch.jit.load('fastdvdnet_traced.pt')
            models['fastdvdnet'].eval()
            print("‚úÖ FastDVDnet –∑–∞–≥—Ä—É–∂–µ–Ω")
        else:
            print("‚ö†Ô∏è FastDVDnet –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ–Ω–æ–π–∑–∏–Ω–≥")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ FastDVDnet: {e}")
        
    # –ó–∞–≥—Ä—É–∂–∞–µ–º RealBasicVSR (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω) 
    try:
        if os.path.exists('realbasicvsr_traced.pt'):
            models['realbasicvsr'] = torch.jit.load('realbasicvsr_traced.pt')
            models['realbasicvsr'].eval()
            print("‚úÖ RealBasicVSR –∑–∞–≥—Ä—É–∂–µ–Ω")
        else:
            print("‚ö†Ô∏è RealBasicVSR –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π upscaling")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RealBasicVSR: {e}")
        
    return models

def extract_frames(video_path, output_dir):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é OpenCV"""
    print(f"üé¨ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∏–∑ {video_path}")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    os.makedirs(output_dir, exist_ok=True)
    frames = []
    
    frame_idx = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        frame_path = os.path.join(output_dir, f"frame_{frame_idx:08d}.png")
        cv2.imwrite(frame_path, frame)
        frames.append(frame_path)
        frame_idx += 1
        
        if frame_idx % 100 == 0:
            print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {frame_idx}/{total_frames} –∫–∞–¥—Ä–æ–≤")
    
    cap.release()
    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(frames)} –∫–∞–¥—Ä–æ–≤")
    return frames, fps

def frames_to_tensor_batch(frame_paths, start_idx, batch_size=5):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –ø–∞—á–∫—É –∫–∞–¥—Ä–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä –¥–ª—è FastDVDnet"""
    frames = []
    
    for i in range(batch_size):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä–∞–Ω–∏—Ü - reflect padding
        frame_idx = start_idx - 2 + i  # —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä –≤ –ø–æ–∑–∏—Ü–∏–∏ 2
        if frame_idx < 0:
            frame_idx = abs(frame_idx)
        elif frame_idx >= len(frame_paths):
            frame_idx = len(frame_paths) - 1 - (frame_idx - len(frame_paths) + 1)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–¥—Ä
        frame = cv2.imread(frame_paths[frame_idx])
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = frame.astype(np.float32) / 255.0
        
        # HWC -> CHW
        frame = np.transpose(frame, (2, 0, 1))
        frames.append(frame)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω —Ç–µ–Ω–∑–æ—Ä: [1, 15, H, W] (5 –∫–∞–¥—Ä–æ–≤ * 3 –∫–∞–Ω–∞–ª–∞)
    frames_tensor = torch.from_numpy(np.stack(frames)).unsqueeze(0)
    frames_tensor = frames_tensor.view(1, 15, frames_tensor.shape[-2], frames_tensor.shape[-1])
    
    return frames_tensor

def tensor_to_frame(tensor):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–µ–Ω–∑–æ—Ä –æ–±—Ä–∞—Ç–Ω–æ –≤ –∫–∞–¥—Ä"""
    # [1, 3, H, W] -> [H, W, 3]
    frame = tensor.squeeze(0).permute(1, 2, 0).numpy()
    frame = np.clip(frame * 255, 0, 255).astype(np.uint8)
    return cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

def denoise_frames(models, frame_paths, output_dir):
    """–î–µ–Ω–æ–π–∑–∏–Ω–≥ –∫–∞–¥—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é FastDVDnet"""
    if 'fastdvdnet' not in models:
        print("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ–Ω–æ–π–∑–∏–Ω–≥ (–º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞)")
        return frame_paths
        
    print("üßπ –î–µ–Ω–æ–π–∑–∏–Ω–≥ –∫–∞–¥—Ä–æ–≤ —Å FastDVDnet...")
    os.makedirs(output_dir, exist_ok=True)
    
    denoised_paths = []
    model = models['fastdvdnet']
    
    for i, frame_path in enumerate(frame_paths):
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—á–∫—É –∏–∑ 5 –∫–∞–¥—Ä–æ–≤
        batch_tensor = frames_to_tensor_batch(frame_paths, i, batch_size=5)
        
        # –î–µ–Ω–æ–π–∑–∏–Ω–≥
        with torch.no_grad():
            denoised_tensor = model(batch_tensor)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        denoised_frame = tensor_to_frame(denoised_tensor)
        output_path = os.path.join(output_dir, f"denoised_{i:08d}.png")
        cv2.imwrite(output_path, denoised_frame)
        denoised_paths.append(output_path)
        
        if (i + 1) % 50 == 0:
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i+1}/{len(frame_paths)} –∫–∞–¥—Ä–æ–≤")
    
    print(f"‚úÖ –î–µ–Ω–æ–π–∑–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(denoised_paths)} –∫–∞–¥—Ä–æ–≤")
    return denoised_paths

def upscale_frames(models, frame_paths, output_dir):
    """–ê–ø—Å–∫–µ–π–ª–∏–Ω–≥ x2 —Å –ø–æ–º–æ—â—å—é RealBasicVSR"""
    print("üìà –ê–ø—Å–∫–µ–π–ª–∏–Ω–≥ x2...")
    os.makedirs(output_dir, exist_ok=True)
    
    upscaled_paths = []
    
    if 'realbasicvsr' in models:
        print("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è RealBasicVSR –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥–∞")
        model = models['realbasicvsr']
    else:
        print("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ–π –±–∏–∫—É–±–∏—á–µ—Å–∫–∏–π –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥")
        model = None
    
    for i, frame_path in enumerate(frame_paths):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–¥—Ä
        frame = cv2.imread(frame_path)
        
        if model is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
            frame_tensor = torch.from_numpy(np.transpose(frame_rgb, (2, 0, 1))).unsqueeze(0)
            
            with torch.no_grad():
                upscaled_tensor = model(frame_tensor)
            
            upscaled_frame = tensor_to_frame(upscaled_tensor)\n        else:\n            # –ü—Ä–æ—Å—Ç–æ–π –±–∏–∫—É–±–∏—á–µ—Å–∫–∏–π –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥\n            h, w = frame.shape[:2]\n            upscaled_frame = cv2.resize(frame, (w*2, h*2), interpolation=cv2.INTER_CUBIC)\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n        output_path = os.path.join(output_dir, f\"upscaled_{i:08d}.png\")\n        cv2.imwrite(output_path, upscaled_frame)\n        upscaled_paths.append(output_path)\n        \n        if (i + 1) % 50 == 0:\n            print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i+1}/{len(frame_paths)} –∫–∞–¥—Ä–æ–≤\")\n    \n    print(f\"‚úÖ –ê–ø—Å–∫–µ–π–ª–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(upscaled_paths)} –∫–∞–¥—Ä–æ–≤\")\n    return upscaled_paths\n\ndef create_video(frame_paths, output_path, fps):\n    \"\"\"–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤\"\"\"\n    print(f\"üé• –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {output_path}\")\n    \n    if not frame_paths:\n        raise ValueError(\"–ù–µ—Ç –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–¥–µ–æ\")\n    \n    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∫–∞–¥—Ä–∞\n    first_frame = cv2.imread(frame_paths[0])\n    height, width = first_frame.shape[:2]\n    \n    # –°–æ–∑–¥–∞–µ–º VideoWriter\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n    \n    for frame_path in frame_paths:\n        frame = cv2.imread(frame_path)\n        out.write(frame)\n    \n    out.release()\n    print(f\"‚úÖ –í–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\")\n\ndef main():\n    parser = argparse.ArgumentParser(description='FastDVDnet + RealBasicVSR x2 Video Enhancement Pipeline')\n    parser.add_argument('input', help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ')\n    parser.add_argument('--output', '-o', help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ', default='enhanced_output.mp4')\n    parser.add_argument('--temp-dir', help='–ü–∞–ø–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤')\n    parser.add_argument('--keep-temp', action='store_true', help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã')\n    \n    args = parser.parse_args()\n    \n    if not os.path.exists(args.input):\n        print(f\"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.input}\")\n        sys.exit(1)\n    \n    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n    if args.temp_dir:\n        temp_base = args.temp_dir\n        os.makedirs(temp_base, exist_ok=True)\n    else:\n        temp_base = tempfile.mkdtemp(prefix='video_enhance_')\n    \n    try:\n        print(f\"üöÄ FastDVDnet + RealBasicVSR x2 Pipeline\")\n        print(f\"–í—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ: {args.input}\")\n        print(f\"–í—ã—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ: {args.output}\")\n        print(f\"–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {temp_base}\")\n        \n        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏\n        models = setup_models()\n        \n        # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã\n        frames_dir = os.path.join(temp_base, 'frames')\n        frame_paths, fps = extract_frames(args.input, frames_dir)\n        \n        # 3. –î–µ–Ω–æ–π–∑–∏–Ω–≥ (FastDVDnet)\n        denoised_dir = os.path.join(temp_base, 'denoised')\n        denoised_paths = denoise_frames(models, frame_paths, denoised_dir)\n        \n        # 4. –ê–ø—Å–∫–µ–π–ª–∏–Ω–≥ x2 (RealBasicVSR)\n        upscaled_dir = os.path.join(temp_base, 'upscaled')\n        upscaled_paths = upscale_frames(models, denoised_paths, upscaled_dir)\n        \n        # 5. –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ\n        create_video(upscaled_paths, args.output, fps)\n        \n        print(f\"\\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!\")\n        print(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç: {args.output}\")\n        \n    finally:\n        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n        if not args.keep_temp and not args.temp_dir:\n            import shutil\n            shutil.rmtree(temp_base)\n            print(f\"üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —É–¥–∞–ª–µ–Ω—ã\")\n        else:\n            print(f\"üìÅ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {temp_base}\")\n\nif __name__ == \"__main__\":\n    main()